{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rd\n",
    "import sys\n",
    "import time\n",
    "import os,re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(object):\n",
    "    def __init__(self, architecture, encoderName):\n",
    "        self._arc = architecture\n",
    "        self._reuse = False\n",
    "        self._scopeName = encoderName\n",
    "        self.variables, self.update_ops, self.saver = None,None,None\n",
    "        self._trainable = None\n",
    "        self._conv = None\n",
    "        self._outputDim = self._arc['outputVectorDim']\n",
    "        self._imgDim = len(self._arc['inputImgDim'])-1\n",
    "        if self._imgDim==2:\n",
    "            self._conv=tf.layers.conv2d\n",
    "        elif self._imgDim==3:\n",
    "            self._conv=tf.layers.conv3d\n",
    "        self._trainable = self._arc['trainable']\n",
    "        self._activation = self._arc['activation']\n",
    "        self._filterNumList = self._arc['filterNumList']\n",
    "        self._kernelSizeList = self._arc['kernelSizeList']\n",
    "        self._stridesList = self._arc['stridesList']\n",
    "    def _convEnc(self, inputs, filters, kernelSize, strides=2, padding='same'):\n",
    "        hiddenC = self._conv(inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, activation=None, trainable=self._trainable, use_bias=False)\n",
    "        hiddenC = tf.layers.batch_normalization(inputs=hiddenC, training=self._bnPhase, trainable=self._trainable)\n",
    "        hiddenC = self._activation(hiddenC)\n",
    "        print hiddenC.shape\n",
    "        return hiddenC\n",
    "    def __call__(self, inputs, bnPhase=True):\n",
    "        with tf.variable_scope(self._scopeName, reuse=self._reuse):\n",
    "            totalDepth = len(self._filterNumList)\n",
    "            for depth in range(totalDepth-1):\n",
    "                filterNum = self._filterNumList[depth]\n",
    "                kernelSize = self._kernelSizeList[depth]\n",
    "                strides = self._stridesList[depth]\n",
    "                if depth==0:\n",
    "                    hidden = inputs\n",
    "                hidden = _convEnc(hidden, filters=filterNum, kernelSize=kernelSize, strides=strides)\n",
    "            hidden = tf.layers.conv2d(hidden, self._filterNumList[totalDepth-1], self._kernelSizeList[totalDepth-1], self._stridesList[totalDepth-1], padding='valid', activation=None, trainable=self._trainable, use_bias=True)\n",
    "            print hidden.shape\n",
    "        self._reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self._scopeName)\n",
    "        self.update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self._scopeName)\n",
    "        self.saver = tf.train.Saver(var_list=self.variables)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder(object):\n",
    "    def __init__(self, architecture, decoderName):\n",
    "        self._arc = architecture\n",
    "        self._reuse = False\n",
    "        self._scopeName = decoderName\n",
    "        self.variables, self.update_ops, self.saver = None,None,None\n",
    "        self._trainable = None\n",
    "        self._convTrans = None\n",
    "        self._outputDim = self._arc['outputVectorDim']\n",
    "        self._imgDim = len(self._arc['inputImgDim'])-1\n",
    "        if self._imgDim==2:\n",
    "            self._convTrans =tf.layers.conv2d_transpose\n",
    "        elif self._imgDim==3:\n",
    "            self._convTrans =tf.layers.conv3d_transpose\n",
    "        self._trainable = self._arc['trainable']\n",
    "        self._activation = self._arc['activation']\n",
    "        self._filterNumList = self._arc['filterNumList']\n",
    "        self._kernelSizeList = self._arc['kernelSizeList']\n",
    "        self._stridesList = self._arc['stridesList']\n",
    "        self._ltOutputDim = self._arc['ltOutputDim']\n",
    "    def _linearTransform(self, inputs, outputDim):\n",
    "        hiddenL = tf.layers.dense(inputs=inputs, units=ouputDim, trainable=self._trainable, use_bias=True)\n",
    "        print hiddenL.shape\n",
    "        return hiddenL\n",
    "    def _convDec(self, inputs, filters, kernelSize, strides, padding='same'):\n",
    "        hiddenC = self._convTrans(inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, activation=None, trainable=self._trainable, use_bias=False)\n",
    "        hiddenC = tf.layers.batch_normalization(inputs=hiddenC, training=self._bnPhase, trainable=self._trainable)\n",
    "        hiddenC = self._activation(hiddenC)\n",
    "        print hiddenC.shape\n",
    "        return hiddenC\n",
    "    def __call__(self, inputs, bnPhase=True):\n",
    "        hidden = self._linearTransform(inputs=inputs, outputDim=self._ltOutputDim)\n",
    "        totalDepth = len(self._filterNumList)\n",
    "        with tf.variable_scope(self._scopeName, reuse=self._reuse):\n",
    "            for depth in range(totalDepth-1):\n",
    "                filterNum = self._filterNumList[depth]\n",
    "                kernelSize = self._kernelSizeList[depth]\n",
    "                strides = self._stridesList[depth]\n",
    "                hidden = self._convDec(hidden, filters=filterNum, kernelSize=kernelSize, strides=strides)\n",
    "        self._reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self._scopeName)\n",
    "        self.update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self._scopeName)\n",
    "        self.saver = tf.train.Saver(var_list=self.variables)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
