{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# make sure to use position 1\n",
    "sys.path.insert(1, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 64)\n",
      "<type 'numpy.float64'>\n",
      "4.31298995018\n",
      "(4096, 64)\n",
      "<type 'numpy.float64'>\n",
      "8.66314506531\n"
     ]
    }
   ],
   "source": [
    "dataPath = '/media/yonsei/4TB_HDD/dataset/suncg_data/training_data/00b052fbc0ce33ea67d9d24cf98b38ea/room-fr_0rm_0-0/voxel3D/objInfo_0/0'\n",
    "iterNum = 200\n",
    "startTime = time.time()\n",
    "for i in range(iterNum):\n",
    "    df = pd.read_hdf(dataPath+'.hdf', 'voxel3D')\n",
    "    df = np.array(df)\n",
    "print df.shape\n",
    "print type(df[0][0])\n",
    "print time.time() - startTime\n",
    "startTime = time.time()\n",
    "for i in range(iterNum):\n",
    "    df = pd.read_csv(dataPath+'.txt', delimiter=' ', dtype=float, header=None)\n",
    "    df = np.array(df)\n",
    "print df.shape\n",
    "print type(df[0][0])\n",
    "print time.time() - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataFile = np.loadtxt('/media/yonsei/4TB_HDD/0.txt')\n",
    "df = pd.DataFrame(dataFile)\n",
    "df.to_hdf('/media/yonsei/4TB_HDD/0.hdf', 'test', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 64)\n",
      "2.68388819695\n",
      "(4096, 64)\n",
      "0.345491170883\n"
     ]
    }
   ],
   "source": [
    "dataFile = '/media/yonsei/4TB_HDD/0.txt'\n",
    "startTime = time.time()\n",
    "for i in range(100):\n",
    "    df = pd.read_csv(dataFile, delimiter=' ', dtype=float, header=None)\n",
    "#     del df\n",
    "print np.array(df).shape\n",
    "print time.time() - startTime\n",
    "\n",
    "dataFile = '/media/yonsei/4TB_HDD/0.hdf'\n",
    "startTime = time.time()\n",
    "for i in range(100):\n",
    "    df = pd.read_hdf(dataFile, 'test')\n",
    "#     del df\n",
    "print np.array(df).shape\n",
    "print time.time() - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('a.txt', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile = '/media/yonsei/4TB_HDD/0.txt'\n",
    "startTime = time.time()\n",
    "df=pd.read_csv(dataFile, delim_whitespace=True, header=None)\n",
    "print np.array(df).shape\n",
    "print time.time() - startTime\n",
    "df = np.array(df)\n",
    "print type(df[0,0])\n",
    "\n",
    "dataFile = '/media/yonsei/4TB_HDD/0.txt'\n",
    "startTime = time.time()\n",
    "df=pd.read_csv(dataFile, delim_whitespace=True, dtype=float, header=None)\n",
    "print np.array(df).shape\n",
    "print time.time() - startTime\n",
    "df = np.array(df)\n",
    "print type(df[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "import os, pickle\n",
    "import src.module.nolbo as nolboModule\n",
    "import dataset_utils.dataset_loader.nolbo as nolboDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nolboConfig = {\n",
    "    'inputImgDim':[416,416,1],\n",
    "    'maxPoolNum':5,\n",
    "    'predictorNumPerGrid':2,\n",
    "    'bboxDim':5,\n",
    "    'class':True, 'zClassDim':64, 'classDim':30,\n",
    "    'inst':True, 'zInstDim':64, 'instDim':1300,\n",
    "    'rot':True, 'zRotDim':3, 'rotDim':3,\n",
    "    'trainable':True,\n",
    "    'decoderStructure':{\n",
    "        'outputImgDim':[64,64,64,1],\n",
    "        'trainable':True,    \n",
    "        'filterNumList':[512,256,128,64,1],\n",
    "        'kernelSizeList':[4,4,4,4,4],\n",
    "        'stridesList':[1,2,2,2,2],\n",
    "        'activation':tf.nn.leaky_relu,\n",
    "        'lastLayerActivation':tf.nn.sigmoid\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = nolboModule.darknet_classifier(\n",
    "    batchSize=36, imgSize=(416,416), lastLayerActivation=tf.nn.sigmoid,\n",
    "    dataPath='./data/classifier_training_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.train(epoch=10, weightSavePath='./weights/classifier/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nolboDataset.nolboDataset(nolboConfig=nolboConfig, mode='singleObject', datasetPath='/media/yonsei/4TB_HDD/dataset/suncg_data/training_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'/media/yonsei/4TB_HDD/dataset/suncg_data/training_data/0a0b9b45a1db29832dd84e80c1347854/room-fr_0rm_0-0/voxel3D/objInfo_0/0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(10):\n",
    "    fuck = dataset.getNextBatch(32)\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(10):\n",
    "    fuck = dataset.getNextBatch(32)\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "a = []\n",
    "b = []\n",
    "for i in range(320):\n",
    "    a.append(None)\n",
    "for i in range(320):\n",
    "    a[i] = pandas.read_csv(os.path.join('/media/yonsei/4TB_HDD/', str(0)+'.txt'), delimiter=' ', dtype=float, header=None)\n",
    "    b.append(a[i])\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in batchData.keys():\n",
    "    print key, batchData[key].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for outputImg in batchData['outputImages']:\n",
    "    print outputImg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(320):\n",
    "    a = np.array(pandas.read_csv(os.path.join('/media/yonsei/4TB_HDD/', str(0) + '.txt'), delimiter=' ', dtype=float, header=None))\n",
    "print time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainNolboSingleObject(\n",
    "    nolboConfig=nolboConfig,\n",
    "    batchSize=32,\n",
    "    training_epoch = 1000,\n",
    "    datasetPath='/media/yonsei/4TB_HDD/dataset/suncg_data/training_data/',\n",
    "    savePath='weights/nolbo_singleObject/',\n",
    "    restorePath='weights/classifier/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNolboSingleObject(\n",
    "    nolboConfig, \n",
    "    batchSize, training_epoch, \n",
    "    datasetPath=None,\n",
    "    savePath = None, restorePath=None):\n",
    "    \n",
    "    dataset = nolboDataset.nolboDataset(nolboConfig=nolboConfig, mode='singleObject', datasetPath=datasetPath)\n",
    "    nb = nolboModule.nolbo_singleObject(config=nolboConfig)\n",
    "    if restorePath!=None:\n",
    "        nb.restoreEncoderCore(restorePath)\n",
    "    loss = np.zeros(2)\n",
    "    epoch = 0\n",
    "    iteration = 0\n",
    "    run_time = 0.0\n",
    "    print 'start training...'\n",
    "    while epoch<training_epoch:\n",
    "        start = time.time()\n",
    "        batchData = dataset.getNextBatch(batchSize=batchSize)\n",
    "        epochCurr = dataset._epoch\n",
    "        dataStart = dataset._dataStart\n",
    "        dataLength = dataset._dataLength\n",
    "        if epochCurr!=epoch:\n",
    "            print ''\n",
    "            iteration = 0\n",
    "            loss = loss*0.0\n",
    "            runTime = 0.0\n",
    "        epoch = epochCurr\n",
    "        lossTemp = np.array(nb.fit(batchDict=batchData))\n",
    "        end = time.time()\n",
    "        loss = (loss*iteration + lossTemp)/(iteration+1.0)\n",
    "        run_time = (run_time*iteration + (end-start))/(iteration + 1.0)\n",
    "\n",
    "        print 'Epoch:{:05d} iter:{:05d} runtime:{:.3f}'.format(int(epoch+1), int(iteration+1), run_time),\\\n",
    "        'curr/total:{:05d}/{:05d}'.format(dataStart,dataLength), \\\n",
    "        'loss= total:{:.3f}, voxel:{:.3f}\\r'.format(loss[0],loss[1]),\n",
    "\n",
    "        if iteration%2000 == 0 and iteration!=0:\n",
    "            print ''\n",
    "            iteration = 0\n",
    "            loss = loss*0.0\n",
    "            runTime = 0.0\n",
    "            if savePath!=None:\n",
    "                print 'save model...'\n",
    "                nb.saveNetworks(savePath)\n",
    "        iteration = iteration + 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainNolbo(nolboConfig=nolboConfig, maxBatchSize=32, training_epoch=10000, restore=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNolbo(nolboConfig, maxBatchSize, training_epoch, restore=False):\n",
    "    dataset = nolboDataset.nolboDataset(nolboConfig=nolboConfig, datasetPath='/media/yonsei/4TB_HDD/dataset/suncg_data/training_data/')\n",
    "    nb = nolboModule.nolbo_multiObject(config=nolboConfig)\n",
    "    if restore == True:\n",
    "        vae.restore_model('./weight_m40')\n",
    "    loss = np.zeros(5)\n",
    "    epoch = 0\n",
    "    iteration = 0\n",
    "    run_time = 0.0\n",
    "    print 'start training...'\n",
    "    while epoch<training_epoch:\n",
    "        start = time.time()\n",
    "        batchData = dataset.getNextBatch(maximumBatchSize=maxBatchSize)\n",
    "        epochCurr = dataset._epoch\n",
    "        dataStart = dataset._dataStart\n",
    "        dataLength = dataset._dataLength\n",
    "        if epochCurr != epoch:\n",
    "            iteration = 0\n",
    "            loss = loss * 0.0\n",
    "            run_time = 0.0\n",
    "        epoch = epochCurr\n",
    "#         print np.sum(batchData[\"objectness\"])\n",
    "        lossTemp = np.array(nb.fit(batchDict = batchData))\n",
    "        end = time.time()\n",
    "        loss = (loss*iteration + lossTemp)/(iteration+1.0)\n",
    "        run_time = (run_time*iteration + (end-start))/(iteration + 1.0)\n",
    "\n",
    "        print 'Epoch:{:05d} iter:{:05d} runtime:{:.3f}'.format(int(epoch+1), int(iteration+1), run_time),\\\n",
    "        'curr/total:{:05d}/{:05d}'.format(dataStart,dataLength), \\\n",
    "        'loss= total:{:.3f}, bbox:{:.3f}, obj:{:.3f}, noObj:{:.3f}, voxel:{:.3f}\\r'.format(loss[0],loss[1],loss[2],loss[3],loss[4]),\n",
    "        if dataStart+maxBatchSize >= dataLength:\n",
    "            print ''\n",
    "            if iteration%2000 == 0:\n",
    "                print 'save model No.'+str(int(iteration%2000)+1)\n",
    "                vae.save_model('./weight_m40')\n",
    "        iteration = iteration + 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainNolbo(nolboConfig=nolboConfig, maxBatchSize=32, training_epoch=10000, restore=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = nolboModule.nolbo_multiObject(config=nolboConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = nolboDataset.nolboDataset(nolboConfig=nolboConfig, datasetPath='/media/yonsei/4TB_HDD/dataset/suncg_data/training_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dataset.getNextBatch(maximumBatchSize=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print a.keys()\n",
    "objectness = a['objectness']\n",
    "bboxHWXY = a['bboxHWXY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print objness.shape\n",
    "print bboxHWXY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuck = np.tile(objness, (1,1,1,2,1))\n",
    "print fuck.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (10*bboxHWXY[0,:,:,0,:]).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = np.random.rand(2,2,3)\n",
    "print a\n",
    "a = a.reshape((2,2,3))\n",
    "inputs = tf.placeholder(tf.float32, shape=(2,2,3))\n",
    "_, indices = tf.nn.top_k(inputs,3)\n",
    "indices = tf.reshape(indices,(-1,3))\n",
    "indices = tf.map_fn(tf.invert_permutation, indices)\n",
    "indices = tf.reshape(indices, (-1,2,3))\n",
    "mask = tf.where(indices<=0, tf.ones_like(indices), tf.zeros_like(indices))\n",
    "sess = tf.Session()\n",
    "b = sess.run(mask, {inputs:a})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.transpose(np.reshape(np.array(\n",
    "            [np.arange(13)] * 13 * 2),\n",
    "(2, 13, 13)), (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print a[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = np.transpose(a, [1,0,2])\n",
    "print at[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
