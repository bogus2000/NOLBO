{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class darknet19_core(object):\n",
    "    def __init__(self, nameScope='dartnet19_core', trainable=True, bnPhase=True, reuse=False, activation = tf.nn.leaky_relu):\n",
    "        self._reuse = reuse\n",
    "        self._trainable = trainable\n",
    "        self._bnPhase = bnPhase\n",
    "        self._nameScope = nameScope\n",
    "        self._activation = activation\n",
    "        self.variables = None\n",
    "        self.update_ops = None\n",
    "        self.saver = None\n",
    "    def _conv(self, inputs, filters, kernel_size):\n",
    "        hiddenC = tf.layers.conv2d(inputs=inputs, filters=filters, kernel_size=kernel_size, strides=1, padding='same', activation=None, trainable=self._trainable, use_bias=False)\n",
    "        hiddenC = tf.layers.batch_normalization(inputs=hiddenC, training=self._bnPhase, trainable=self._trainable)\n",
    "        hiddenC = self._activation(hiddenC)\n",
    "        print hiddenC.shape\n",
    "        return hiddenC\n",
    "    def _maxPool(self, inputs, pool_size=(2,2), strides=2, padding='same'):\n",
    "        hiddenP = tf.layers.max_pooling2d(inputs, pool_size=pool_size, strides=strides, padding=padding)\n",
    "        print hiddenP.shape\n",
    "        return hiddenP\n",
    "    def __call__(self, inputImg):\n",
    "        with tf.variable_scope(self._nameScope, reuse=self._reuse):\n",
    "            hiddenC1 = self._conv(inputs=inputImg, filters=32, kernel_size=3)\n",
    "            hiddenP1 = self._maxPool(inputs=hiddenC1)\n",
    "            \n",
    "            hiddenC2 = self._conv(inputs=hiddenP1, filters=64, kernel_size=3)\n",
    "            hiddenP2 = self._maxPool(inputs=hiddenC2)\n",
    "            \n",
    "            hiddenC31 = self._conv(inputs=hiddenP2, filters=128, kernel_size=3)\n",
    "            hiddenC32 = self._conv(inputs=hiddenC31, filters=64, kernel_size=1)\n",
    "            hiddenC33 = self._conv(inputs=hiddenC32, filters=128, kernel_size=3)\n",
    "            hiddenP3 = self._maxPool(inputs=hiddenC33)\n",
    "            \n",
    "            hiddenC41 = self._conv(inputs=hiddenP3, filters=256, kernel_size=3)\n",
    "            hiddenC42 = self._conv(inputs=hiddenC41, filters=128, kernel_size=1)\n",
    "            hiddenC43 = self._conv(inputs=hiddenC42, filters=256, kernel_size=3)\n",
    "            hiddenP4 = self._maxPool(inputs=hiddenC43)\n",
    "            \n",
    "            hiddenC51 = self._conv(inputs=hiddenP4, filters=512, kernel_size=3)\n",
    "            hiddenC52 = self._conv(inputs=hiddenC51, filters=256, kernel_size=1)\n",
    "            hiddenC53 = self._conv(inputs=hiddenC52, filters=512, kernel_size=3)\n",
    "            hiddenC54 = self._conv(inputs=hiddenC53, filters=256, kernel_size=1)\n",
    "            hiddenC55 = self._conv(inputs=hiddenC54, filters=512, kernel_size=3)\n",
    "            hiddenP5 = self._maxPool(inputs=hiddenC55)\n",
    "            \n",
    "            hiddenC61 = self._conv(inputs=hiddenP5, filters=1024, kernel_size=3)\n",
    "            hiddenC62 = self._conv(inputs=hiddenC61, filters=512, kernel_size=1)\n",
    "            hiddenC63 = self._conv(inputs=hiddenC62, filters=1024, kernel_size=3)\n",
    "            hiddenC64 = self._conv(inputs=hiddenC63, filters=512, kernel_size=1)\n",
    "            hiddenC65 = self._conv(inputs=hiddenC64, filters=1024, kernel_size=3)\n",
    "        self._reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self._nameScope)\n",
    "        self.update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self._nameScope)\n",
    "        self.saver = tf.train.Saver(var_list=self.variables)\n",
    "        outputs = hiddenC65\n",
    "        return outputs\n",
    "class darknet19_pretraining(object):\n",
    "    def __init__(self, classNum, nameScope='darknet19_pretraining', trainable=True, bnPhase=True, reuse=False, activation = tf.nn.leaky_relu):\n",
    "        self._classNum = classNum\n",
    "        self._nameScope = nameScope\n",
    "        self._trainable = trainable\n",
    "        self._bnPhase = bnPhase\n",
    "        self._reuse = reuse\n",
    "        self._activation = activation\n",
    "        self.variables = None\n",
    "        self.update_ops = None\n",
    "        self.saver = None\n",
    "    def __call__(self, inputImg):\n",
    "        with tf.variable_scope(self._nameScope, reuse=self._reuse):\n",
    "            hiddenC1 = tf.layers.conv2d(inputs=inputImg, filters=self._classNum, kernel_size=1, strides=1, padding='same', activation=None, trainable=self._trainable, use_bias=True)\n",
    "            hiddenP1 = tf.reduce_mean(hiddenC1, axis=[1,2])\n",
    "            hiddenB1 = tf.nn.sigmoid(hiddenP1)\n",
    "            print hiddenB1.shape\n",
    "        self._reuse=True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self._nameScope)\n",
    "        self.update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope=self._nameScope)\n",
    "        self.saver = tf.train.Saver(var_list=self.variables)\n",
    "        outputs = hiddenB1\n",
    "        return outputs\n",
    "class darknet_classifier(object):\n",
    "    def __init__(self, dataPath='./', imgSize = (416,416), batchSize = 64, learningRate = 0.001):\n",
    "        self._imgList = None\n",
    "        self._imgClassList = None\n",
    "        self._dataPath = dataPath\n",
    "        self._imgSize = imgSize\n",
    "        self._batchSize = batchSize\n",
    "        self._lr = learningRate\n",
    "        self._classNum = None\n",
    "        self.variables = None\n",
    "        self.update_ops = None\n",
    "        self._inputImg = None\n",
    "        self._outputClass = None\n",
    "        self._outputClassGT = None\n",
    "        self._optimizer = None\n",
    "        self._loss = None\n",
    "        self._loadDataset()\n",
    "        self._buildNetwork()\n",
    "        self._createLossAndOptimizer()\n",
    "        #init the session\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.90)\n",
    "        self._sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))        \n",
    "        #initialize variables\n",
    "        init = tf.group(\n",
    "            tf.global_variables_initializer(),\n",
    "            tf.local_variables_initializer()\n",
    "        )\n",
    "        #launch the session\n",
    "        self._sess.run(init)\n",
    "    def _loadDataset(self):\n",
    "        print \"load Dataset...\"\n",
    "        self._imgList = []\n",
    "        imgListTemp = np.load(os.path.join(self._dataPath,'imgList.npy'))\n",
    "        self._imgClassList = np.load(os.path.join(self._dataPath+'imgClassList.npy'))\n",
    "        self._classNum = self._imgClassList.shape[1]\n",
    "        for i in range(len(imgListTemp)):\n",
    "            img = cv2.resize(imgListTemp[i], self._imgSize)\n",
    "            img = img.reshape((self._imgSize[0], self._imgSize[1],1))\n",
    "            self._imgList.append(img)\n",
    "        self._imgList = np.array(self._imgList)\n",
    "        print \"done!\"\n",
    "    def _buildNetwork(self):\n",
    "        print \"build network...\"\n",
    "        self._inputImg = tf.placeholder(tf.float32, shape=(None, self._imgSize[0], self._imgSize[1], 1))\n",
    "        self._outputClassGT = tf.placeholder(tf.float32, shape=(None, self._classNum))\n",
    "        self._darknetCore = darknet19_core()\n",
    "        self._pretraining = darknet19_pretraining(self._classNum)\n",
    "        coreOutput = self._darknetCore(self._inputImg)\n",
    "        self._outputClass = self._pretraining(coreOutput)\n",
    "        print \"done!\"\n",
    "    def _createLossAndOptimizer(self):\n",
    "        print \"create loss and optimizer...\"\n",
    "        self._optimizer = tf.train.AdamOptimizer(learning_rate=self._lr)\n",
    "        def binaryLoss(xPred, xTarget, epsilon=1e-7):\n",
    "            yTarget = xTarget\n",
    "            yPred = tf.clip_by_value(xPred, clip_value_min=epsilon, clip_value_max=1.0-epsilon)\n",
    "            bce_loss = - tf.reduce_sum(yTarget*tf.log(yPred) + (1.0-yTarget)*tf.log(1.0-yPred), axis=-1)\n",
    "            return bce_loss\n",
    "        self._loss = tf.reduce_mean(binaryLoss(xPred=self._outputClass, xTarget=self._outputClassGT))\n",
    "        with tf.control_dependencies(self._darknetCore.update_ops + self._pretraining.update_ops):\n",
    "            self._optimizer = self._optimizer.minimize(\n",
    "                self._loss, var_list = self._darknetCore.variables + self._pretraining.variables\n",
    "            )\n",
    "        print \"done!\"\n",
    "    def _saveNetwork(self, savePath='./'):\n",
    "        dCorePath = os.path.join(savePath,'/dCore.ckpt')\n",
    "        pretrainPath = os.path.join(savePath,'/pretrain.ckpt')\n",
    "        self._darknetCore.saver.save(dCorePath)\n",
    "        self._pretraining.saver.save(pretrainPath)\n",
    "    def _restoreNetwork(self, restorePath='./'):\n",
    "        dCorePath = os.path.join(restorePath,'/dCore.ckpt')\n",
    "        pretrainPath = os.path.join(restorePath,'/pretrain.ckpt')\n",
    "        self._darknetCore.saver.restore(dCorePath)\n",
    "        self._pretraining.saver.restore(pretrainPath)\n",
    "    def _fit(self, batchImg, batchClassIndex):\n",
    "        feed_dict = {\n",
    "            self._inputImg : batchImg,\n",
    "            self._outputClassGT : batchClassIndex\n",
    "        }\n",
    "        acc = (tf.reduce_sum((1-self._outputClass)*(1-self._outputClassGT))+tf.reduce_sum(self._outputClass*self._outputClassGT))\\\n",
    "        /(tf.reduce_sum(self._outputClassGT)+tf.reduce_sum(1-self._outputClassGT))\n",
    "        _, lossResult = self._sess.run([self._optimizer, self._loss], feed_dict=feed_dict)\n",
    "        accResult = self._sess.run(acc, feed_dict=feed_dict)\n",
    "        return accResult, lossResult\n",
    "    def train(self, epoch = 10000):\n",
    "        currEpoch = 0\n",
    "        dataCompleted = 0\n",
    "        loss = 0\n",
    "        acc = 0\n",
    "        runTime = 0\n",
    "        for i in range(int(epoch/self._batchSize)):\n",
    "            for i in range(int(len(self._imgList)/self._batchSize)):\n",
    "                startTime = time.time()\n",
    "                start = i * self._batchSize\n",
    "                end = np.min((start+self._batchSize, len(self._imgList)))\n",
    "                accTemp, lossTemp = self._fit(self._imgList[start:end], self._imgClassList[start:end])\n",
    "                endTime = time.time()\n",
    "                runTimeTemp = endTime - startTime\n",
    "                acc = float(acc*currEpoch + accTemp)/float(currEpoch+1.0)\n",
    "                loss = float(loss*currEpoch + lossTemp)/float(currEpoch+1.0)\n",
    "                runTime = float(runTime*currEpoch + runTimeTemp)/(currEpoch+1.0)\n",
    "                sys.stdout.write('Epoch:{:05d} round:{:04d} runtime:{:.3f} '.format(int(currEpoch+1), int(dataCompleted+1), runTime))\n",
    "                sys.stdout.write('curr/total:{:05d}/{:05d} '.format(start, len(self._imgList)))\n",
    "                sys.stdout.write('loss:{:.3f} acc:{:.3f}\\r'.format(loss, acc))\n",
    "                currEpoch += 1\n",
    "                if currEpoch%1000 == 0:\n",
    "                    self._saveNetwork()\n",
    "            dataCompleted +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load Dataset...\n",
      "done!\n",
      "build network...\n",
      "(?, 416, 416, 32)\n",
      "(?, 208, 208, 32)\n",
      "(?, 208, 208, 64)\n",
      "(?, 104, 104, 64)\n",
      "(?, 104, 104, 128)\n",
      "(?, 104, 104, 64)\n",
      "(?, 104, 104, 128)\n",
      "(?, 52, 52, 128)\n",
      "(?, 52, 52, 256)\n",
      "(?, 52, 52, 128)\n",
      "(?, 52, 52, 256)\n",
      "(?, 26, 26, 256)\n",
      "(?, 26, 26, 512)\n",
      "(?, 26, 26, 256)\n",
      "(?, 26, 26, 512)\n",
      "(?, 26, 26, 256)\n",
      "(?, 26, 26, 512)\n",
      "(?, 13, 13, 512)\n",
      "(?, 13, 13, 1024)\n",
      "(?, 13, 13, 512)\n",
      "(?, 13, 13, 1024)\n",
      "(?, 13, 13, 512)\n",
      "(?, 13, 13, 1024)\n",
      "(?, 24)\n",
      "done!\n",
      "create loss and optimizer...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "darkClassifier = darknet_classifier(batchSize=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0224 round:001 runtime:0.731 curr/total:07136/10291 loss:5.291 acc:0.8865\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f50ed5a1f22e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdarkClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-72c41f6e718d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batchSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imgList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                 \u001b[0maccTemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossTemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imgList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imgClassList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0mendTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mrunTimeTemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendTime\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstartTime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-72c41f6e718d>\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, batchImg, batchClassIndex)\u001b[0m\n\u001b[1;32m    158\u001b[0m         }\n\u001b[1;32m    159\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputClassGT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputClass\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputClassGT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputClassGT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputClassGT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0maccResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "darkClassifier.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
